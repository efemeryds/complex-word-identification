{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c928011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART C:  Modeling the task\n",
    "\n",
    "#For part C, we use an implementation for a vanilla LSTM which was originally developed for a \n",
    "# named entity recognition project for a Stanford course. \n",
    "#You can find more documentation here: https://github.com/cs230-stanford/cs230-code-examples/tree/master/pytorch/nlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b127443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Understanding the code\n",
    "\n",
    "# Answer in your own words (1-3 sentences per question)\n",
    "# Run the file build_vocab.py. What does this script do? \n",
    "\n",
    "#Output:\n",
    "#Characteristics of the dataset:\n",
    "#- train_size: 653\n",
    "#- dev_size: 85\n",
    "#- test_size: 19\n",
    "#- vocab_size: 4119\n",
    "#- number_of_tags: 2\n",
    "#- pad_word: <pad>\n",
    "#- pad_tag: N\n",
    "#- unk_word: UNK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf3805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the file model/net.py. Which layers are being used and what is their function?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ed7eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How could you change the loss function of the model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8bdf019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12.Detailed evaluation\n",
    "#Train the model on the data in preprocessed/train and preprocessed/dev by running the code in train.py. \n",
    "\n",
    "#Output:\n",
    "\n",
    "# Epoch 6/10\n",
    "# 100%|██████████| 130/130 [00:01<00:00, 82.60it/s, loss=0.205]\n",
    "# - Train metrics: accuracy: 0.934 ; loss: 0.180\n",
    "# - Eval metrics : accuracy: 0.866 ; loss: 0.288\n",
    "# Checkpoint Directory exists! \n",
    "# - Found new best accuracy\n",
    "\n",
    "# Epoch 9/10\n",
    "# 100%|██████████| 130/130 [00:01<00:00, 67.04it/s, loss=0.107]\n",
    "# - Train metrics: accuracy: 0.958 ; loss: 0.091\n",
    "# Checkpoint Directory exists! \n",
    "# - Eval metrics : accuracy: 0.868 ; loss: 0.323\n",
    "# - Found new best accuracy\n",
    "# Epoch 10/10\n",
    "# 100%|██████████| 130/130 [00:02<00:00, 62.54it/s, loss=0.083]\n",
    "# - Train metrics: accuracy: 0.964 ; loss: 0.074\n",
    "# - Eval metrics : accuracy: 0.866 ; loss: 0.344\n",
    "# Checkpoint Directory exists! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e8547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model on the data in preprocessed/test by running evaluate.py. \n",
    "\n",
    "#Output: \n",
    "# Eval metrics : accuracy: 0.852 ; loss: 0.365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c0a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The original code only outputs the accuracy and the loss of the model. \n",
    "# I adapted the code, so that it writes the predictions to experiments/base_model/model_output.tsv.\n",
    "#Implement calculations for precision, recall, and F1 for each class in TODO_detailed_evaluation.py. \n",
    "# You can use existing functions but make sure that you understand how they work. \n",
    "#Provide the results for the baselines and the LSTM in the table below. \n",
    "\n",
    "#|----------|-------------------------|---------------------------|------------------|\n",
    "#|Model     |       Class N           |       Class C             | Weighted Average |\n",
    "#|----------|-------------------------|---------------------------|------------------|\n",
    "#|          |Precision | Recall |  F1 |  Precision | Recall | F1  |          F1      |\n",
    "#|----------|----------|--------|-----|------------|--------|-----|------------------|\n",
    "#|Random    |          |        |     |            |        |     |                  |\n",
    "#|----------|----------|--------|-----|------------|--------|-----|------------------|\n",
    "#|Majority  |          |        |     |            |        |     |                  |\n",
    "#|----------|----------|--------|-----|------------|--------|-----|------------------|\n",
    "#|Length    |          |        |     |            |        |     |                  |\n",
    "#|----------|----------|--------|-----|------------|--------|-----|------------------|\n",
    "#|Frequency |          |        |     |            |        |     |                  |\n",
    "#|----------|----------|--------|-----|------------|--------|-----|------------------|\n",
    "#|LSTM      |          |        |     |            |        |     |                  |\n",
    "#|----------|----------|--------|-----|------------|--------|-----|------------------|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47bea353",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13.Interpretation\n",
    "#Compare the performance to the results in the shared task (https://aclanthology.org/W18-0507.pdf) \n",
    "# and interpret the results in 3-5 sentences. \n",
    "#Don’t forget to check the number of instances in the training and test data and integrate this into your reflection.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0738f76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14.Experiments\n",
    "#Vary a hyperparameter of your choice and plot the F1-results (weighted average) for at least 5 different values. \n",
    "#Examples for hyperparameters are embedding size, learning rate, number of epochs, random seed,\n",
    "\n",
    "#Hyperparameter: \n",
    "#Plot:\n",
    "\n",
    "\n",
    "#Interpret the result (2-4 sentences): \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Provide 3 examples for which the label changes when the hyperparameter changes:\n",
    "#1.Example 1, Label at Value 1, Label at Value 2\n",
    "#2.Example 2, Label at Value 1, Label at Value 2\n",
    "#.Example 3, Label at Value 1, Label at Value 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
